name: Test Notebook Execution

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
    paths:
      - 'examples/*.ipynb'
      - 'src/**'
      - 'tests/test_notebook_execution.py'
      - 'tests/test_production_notebook.py'
      - '.github/workflows/test-notebooks-execution.yml'
  workflow_dispatch:

jobs:
  test-notebooks:
    name: Execute Notebooks
    runs-on: ubuntu-latest
    timeout-minutes: 30
    if: github.event_name == 'push' || github.event_name == 'workflow_dispatch' || github.event_name == 'pull_request'
    
    strategy:
      fail-fast: false
      matrix:
        notebook:
          - colab_quickstart.ipynb
          - 01_getting_started.ipynb
          - 02_quantum_vs_classical.ipynb
          - 03_advanced_visualization.ipynb
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v6
    
    - name: Set up Python 3.10
      uses: actions/setup-python@v6
      with:
        python-version: '3.10'
        cache: 'pip'
    
    - name: Cache pip packages
      uses: actions/cache@v5
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-notebooks-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-notebooks-
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        
        # Critical version pinning for autoray/PennyLane compatibility
        pip uninstall -y numpy jax jaxlib autograd pennylane autoray 2>/dev/null || true
        
        # Install in correct order with strict versions
        pip install 'numpy>=1.23.0,<2.0.0'
        pip install 'autoray>=0.6.1,<0.7.0'  # Compatible with PennyLane NumpyMimic
        pip install 'autograd>=1.6.2'
        pip install 'pennylane>=0.33.0,<0.35.0'
        
        # Install package with test dependencies
        pip install -e .[dev,protein-lm]
        
        # Install notebook execution tools
        pip install nbconvert nbformat jupyter ipykernel
    
    - name: Verify NumPy version
      run: |
        python -c "import numpy; print(f'NumPy version: {numpy.__version__}')"
        python -c "import numpy; assert numpy.__version__ < '2.0', 'NumPy 2.0+ detected!'"
    
    - name: Execute notebook
      run: |
        echo "Testing ${{ matrix.notebook }}..."
        jupyter nbconvert --to notebook --execute \
          --ExecutePreprocessor.timeout=600 \
          --ExecutePreprocessor.kernel_name=python3 \
          --output-dir=/tmp/executed \
          examples/${{ matrix.notebook }}
        
        echo "Notebook executed successfully!"
    
    - name: Validate outputs
      run: |
        python -c "
        import nbformat
        import sys
        
        nb_path = '/tmp/executed/${{ matrix.notebook }}'
        with open(nb_path, 'r') as f:
            nb = nbformat.read(f, as_version=4)
        
        # Count cells with outputs
        code_cells = sum(1 for c in nb.cells if c.cell_type == 'code')
        cells_with_output = sum(1 for c in nb.cells if c.cell_type == 'code' and c.outputs)
        errors = sum(1 for c in nb.cells if c.cell_type == 'code' and any(o.output_type == 'error' for o in c.outputs))
        
        print(f'Code cells: {code_cells}')
        print(f'Cells with output: {cells_with_output}')
        print(f'Cells with errors: {errors}')
        
        if errors > 0:
            print('Notebook has errors!')
            sys.exit(1)
        
        if cells_with_output == 0:
            print('No outputs generated!')
            sys.exit(1)
        
        print('Notebook validation passed!')
        "
    
    - name: Upload executed notebook
      if: always()
      uses: actions/upload-artifact@v6
      with:
        name: executed-${{ matrix.notebook }}
        path: /tmp/executed/${{ matrix.notebook }}
        retention-days: 7
  
  test-notebook-structure:
    name: Test Notebook Structure
    runs-on: ubuntu-latest
    if: github.event_name == 'push' || github.event_name == 'workflow_dispatch' || github.event_name == 'pull_request'
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v6
    
    - name: Set up Python 3.10
      uses: actions/setup-python@v6
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        pip install --upgrade pip
        # Add nbconvert for ExecutePreprocessor import in test file
        pip install pytest nbformat nbconvert torch
    
    - name: Run structure tests
      run: |
        pytest tests/test_notebook_execution.py::TestNotebookStructure -v
    
    - name: Run content tests
      run: |
        pytest tests/test_notebook_execution.py::TestNotebookContent -v
  
  test-production-notebook:
    name: Test Production Notebook
    runs-on: ubuntu-latest
    if: github.event_name == 'push' || github.event_name == 'workflow_dispatch' || github.event_name == 'pull_request'
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v6
    
    - name: Set up Python 3.10
      uses: actions/setup-python@v6
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install pytest nbformat nbconvert torch pandas matplotlib seaborn psutil
    
    - name: Test notebook structure
      run: |
        pytest tests/test_production_notebook.py::TestNotebookStructure -v
    
    - name: Test configuration cells
      run: |
        pytest tests/test_production_notebook.py::TestConfigurationCells -v
    
    - name: Test data processing
      run: |
        pytest tests/test_production_notebook.py::TestDataProcessing -v
    
    - name: Test model training
      run: |
        pytest tests/test_production_notebook.py::TestModelTraining -v
    
    - name: Test evaluation
      run: |
        pytest tests/test_production_notebook.py::TestEvaluation -v
    
    - name: Test visualization
      run: |
        pytest tests/test_production_notebook.py::TestVisualization -v
    
    - name: Test results export
      run: |
        pytest tests/test_production_notebook.py::TestResultsExport -v
    
    - name: Test memory management
      run: |
        pytest tests/test_production_notebook.py::TestMemoryManagement -v
    
    - name: Test error handling
      run: |
        pytest tests/test_production_notebook.py::TestErrorHandling -v
    
    - name: Test reproducibility
      run: |
        pytest tests/test_production_notebook.py::TestReproducibility -v
    
    - name: Test documentation
      run: |
        pytest tests/test_production_notebook.py::TestDocumentation -v
  
  summary:
    name: Test Summary
    if: always()
    needs: [test-notebooks, test-notebook-structure, test-production-notebook]
    runs-on: ubuntu-latest
    
    steps:
    - name: Check test results
      run: |
        echo "## Notebook Execution Test Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [[ "${{ needs.test-notebooks.result }}" == "success" ]]; then
          echo "✅ All tutorial notebooks executed successfully!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Tested Notebooks" >> $GITHUB_STEP_SUMMARY
          echo "- colab_quickstart.ipynb" >> $GITHUB_STEP_SUMMARY
          echo "- 01_getting_started.ipynb" >> $GITHUB_STEP_SUMMARY
          echo "- 02_quantum_vs_classical.ipynb" >> $GITHUB_STEP_SUMMARY
          echo "- 03_advanced_visualization.ipynb" >> $GITHUB_STEP_SUMMARY
        else
          echo "❌ Some notebooks failed execution" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Check individual job logs for details." >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [[ "${{ needs.test-notebook-structure.result }}" == "success" ]]; then
          echo "✅ Notebook structure tests passed!" >> $GITHUB_STEP_SUMMARY
        else
          echo "❌ Notebook structure tests failed" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [[ "${{ needs.test-production-notebook.result }}" == "success" ]]; then
          echo "✅ Production notebook tests passed!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Production Notebook Validation" >> $GITHUB_STEP_SUMMARY
          echo "- Structure and metadata ✅" >> $GITHUB_STEP_SUMMARY
          echo "- Configuration cells ✅" >> $GITHUB_STEP_SUMMARY
          echo "- Data processing ✅" >> $GITHUB_STEP_SUMMARY
          echo "- Model training ✅" >> $GITHUB_STEP_SUMMARY
          echo "- Evaluation and statistics ✅" >> $GITHUB_STEP_SUMMARY
          echo "- Visualization ✅" >> $GITHUB_STEP_SUMMARY
          echo "- Results export ✅" >> $GITHUB_STEP_SUMMARY
          echo "- Memory management ✅" >> $GITHUB_STEP_SUMMARY
          echo "- Error handling ✅" >> $GITHUB_STEP_SUMMARY
          echo "- Reproducibility ✅" >> $GITHUB_STEP_SUMMARY
          echo "- Documentation ✅" >> $GITHUB_STEP_SUMMARY
        else
          echo "❌ Production notebook tests failed" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Check test logs for details." >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### Artifacts" >> $GITHUB_STEP_SUMMARY
        echo "Executed notebooks are available as workflow artifacts for 7 days." >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### Compatibility Fixes Applied" >> $GITHUB_STEP_SUMMARY
        echo "- NumPy <2.0 for stability" >> $GITHUB_STEP_SUMMARY
        echo "- Autoray <0.7.0 for PennyLane compatibility" >> $GITHUB_STEP_SUMMARY
