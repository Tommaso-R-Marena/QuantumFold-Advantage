{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum vs Classical Comparison\n",
    "\n",
    "This notebook demonstrates the difference between quantum-enhanced and purely classical predictions.\n",
    "\n",
    "## Objectives\n",
    "1. Train both quantum and classical models\n",
    "2. Compare prediction quality\n",
    "3. Analyze computational performance\n",
    "4. Identify cases where quantum helps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "from src.model import QuantumFoldModel\n",
    "from src.quantum_layers import HybridQuantumClassicalBlock\n",
    "from src.benchmarks import ProteinStructureEvaluator\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Models\n",
    "\n",
    "Create two models: one with quantum layers and one purely classical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Quantum-enhanced model\n",
    "model_quantum = QuantumFoldModel(\n",
    "    n_layers=4,\n",
    "    embed_dim=64,\n",
    "    n_heads=4,\n",
    "    use_quantum=True,\n",
    "    n_qubits=4\n",
    ").to(device)\n",
    "\n",
    "# Classical baseline\n",
    "model_classical = QuantumFoldModel(\n",
    "    n_layers=4,\n",
    "    embed_dim=64,\n",
    "    n_heads=4,\n",
    "    use_quantum=False,\n",
    "    n_qubits=0\n",
    ").to(device)\n",
    "\n",
    "print(f\"Quantum model parameters: {sum(p.numel() for p in model_quantum.parameters()):,}\")\n",
    "print(f\"Classical model parameters: {sum(p.numel() for p in model_classical.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Benchmark Inference Speed\n",
    "\n",
    "Compare computational performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create dummy input\n",
    "batch_size = 1\n",
    "seq_len = 100\n",
    "embed_dim = 64\n",
    "\n",
    "dummy_input = {\n",
    "    'sequence_encoding': torch.randn(batch_size, seq_len, 20).to(device),\n",
    "    'sequence_length': torch.tensor([seq_len]).to(device)\n",
    "}\n",
    "\n",
    "# Warmup\n",
    "for _ in range(5):\n",
    "    with torch.no_grad():\n",
    "        _ = model_quantum(dummy_input)\n",
    "        _ = model_classical(dummy_input)\n",
    "\n",
    "# Benchmark quantum\n",
    "n_runs = 10\n",
    "times_quantum = []\n",
    "model_quantum.eval()\n",
    "\n",
    "for _ in range(n_runs):\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        _ = model_quantum(dummy_input)\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "    times_quantum.append(time.time() - start)\n",
    "\n",
    "# Benchmark classical\n",
    "times_classical = []\n",
    "model_classical.eval()\n",
    "\n",
    "for _ in range(n_runs):\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        _ = model_classical(dummy_input)\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "    times_classical.append(time.time() - start)\n",
    "\n",
    "# Results\n",
    "print(f\"\\nInference Time (100 residues, {n_runs} runs):\")\n",
    "print(f\"  Quantum:   {np.mean(times_quantum)*1000:.1f} ± {np.std(times_quantum)*1000:.1f} ms\")\n",
    "print(f\"  Classical: {np.mean(times_classical)*1000:.1f} ± {np.std(times_classical)*1000:.1f} ms\")\n",
    "print(f\"  Overhead:  {np.mean(times_quantum)/np.mean(times_classical):.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Speed Comparison\n",
    "\n",
    "Plot inference times across different sequence lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test different sequence lengths\n",
    "seq_lengths = [50, 100, 200, 300]\n",
    "quantum_times = []\n",
    "classical_times = []\n",
    "\n",
    "for seq_len in seq_lengths:\n",
    "    test_input = {\n",
    "        'sequence_encoding': torch.randn(1, seq_len, 20).to(device),\n",
    "        'sequence_length': torch.tensor([seq_len]).to(device)\n",
    "    }\n",
    "    \n",
    "    # Quantum\n",
    "    times = []\n",
    "    for _ in range(5):\n",
    "        start = time.time()\n",
    "        with torch.no_grad():\n",
    "            _ = model_quantum(test_input)\n",
    "        if device == 'cuda':\n",
    "            torch.cuda.synchronize()\n",
    "        times.append(time.time() - start)\n",
    "    quantum_times.append(np.mean(times))\n",
    "    \n",
    "    # Classical\n",
    "    times = []\n",
    "    for _ in range(5):\n",
    "        start = time.time()\n",
    "        with torch.no_grad():\n",
    "            _ = model_classical(test_input)\n",
    "        if device == 'cuda':\n",
    "            torch.cuda.synchronize()\n",
    "        times.append(time.time() - start)\n",
    "    classical_times.append(np.mean(times))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(seq_lengths, [t*1000 for t in quantum_times], 'o-', label='Quantum', linewidth=2)\n",
    "plt.plot(seq_lengths, [t*1000 for t in classical_times], 's-', label='Classical', linewidth=2)\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Inference Time (ms)')\n",
    "plt.title('Computational Performance: Quantum vs Classical')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prediction Quality Comparison\n",
    "\n",
    "Compare actual prediction accuracy on test proteins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate synthetic test data\n",
    "n_test = 20\n",
    "test_results_quantum = []\n",
    "test_results_classical = []\n",
    "evaluator = ProteinStructureEvaluator()\n",
    "\n",
    "for i in range(n_test):\n",
    "    # Create synthetic data\n",
    "    seq_len = np.random.randint(50, 150)\n",
    "    test_input = {\n",
    "        'sequence_encoding': torch.randn(1, seq_len, 20).to(device),\n",
    "        'sequence_length': torch.tensor([seq_len]).to(device)\n",
    "    }\n",
    "    \n",
    "    # Ground truth (synthetic)\n",
    "    coords_true = np.random.randn(seq_len, 3) * 10\n",
    "    \n",
    "    # Quantum prediction\n",
    "    with torch.no_grad():\n",
    "        pred_quantum = model_quantum(test_input)\n",
    "    coords_quantum = pred_quantum['coordinates'].cpu().numpy()[0]\n",
    "    \n",
    "    # Classical prediction\n",
    "    with torch.no_grad():\n",
    "        pred_classical = model_classical(test_input)\n",
    "    coords_classical = pred_classical['coordinates'].cpu().numpy()[0]\n",
    "    \n",
    "    # Evaluate\n",
    "    metrics_q = evaluator.evaluate_structure(coords_quantum, coords_true, seq_len)\n",
    "    metrics_c = evaluator.evaluate_structure(coords_classical, coords_true, seq_len)\n",
    "    \n",
    "    test_results_quantum.append(metrics_q.to_dict())\n",
    "    test_results_classical.append(metrics_c.to_dict())\n",
    "\n",
    "print(f\"Evaluated {n_test} test proteins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Extract metrics\n",
    "metrics_names = ['rmsd', 'tm_score', 'gdt_ts', 'lddt']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, metric in enumerate(metrics_names):\n",
    "    values_q = [r[metric] for r in test_results_quantum]\n",
    "    values_c = [r[metric] for r in test_results_classical]\n",
    "    \n",
    "    ax = axes[idx]\n",
    "    \n",
    "    positions = [1, 2]\n",
    "    data = [values_c, values_q]\n",
    "    \n",
    "    bp = ax.boxplot(data, positions=positions, widths=0.6, patch_artist=True,\n",
    "                     labels=['Classical', 'Quantum'])\n",
    "    \n",
    "    # Color boxes\n",
    "    bp['boxes'][0].set_facecolor('lightblue')\n",
    "    bp['boxes'][1].set_facecolor('lightcoral')\n",
    "    \n",
    "    ax.set_ylabel(metric.upper())\n",
    "    ax.set_title(f'{metric.upper()} Comparison')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add mean values\n",
    "    mean_c = np.mean(values_c)\n",
    "    mean_q = np.mean(values_q)\n",
    "    ax.text(1, mean_c, f'{mean_c:.3f}', ha='center', va='bottom')\n",
    "    ax.text(2, mean_q, f'{mean_q:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # Statistical test\n",
    "    from scipy import stats\n",
    "    t_stat, p_value = stats.ttest_ind(values_q, values_c)\n",
    "    ax.text(1.5, ax.get_ylim()[1]*0.95, f'p={p_value:.4f}', ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nSummary Statistics:\")\n",
    "for metric in metrics_names:\n",
    "    values_q = [r[metric] for r in test_results_quantum]\n",
    "    values_c = [r[metric] for r in test_results_classical]\n",
    "    \n",
    "    print(f\"\\n{metric.upper()}:\")\n",
    "    print(f\"  Classical: {np.mean(values_c):.4f} ± {np.std(values_c):.4f}\")\n",
    "    print(f\"  Quantum:   {np.mean(values_q):.4f} ± {np.std(values_q):.4f}\")\n",
    "    improvement = ((np.mean(values_q) - np.mean(values_c)) / np.mean(values_c)) * 100\n",
    "    print(f\"  Improvement: {improvement:+.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "From this analysis, we can observe:\n",
    "\n",
    "1. **Computational Cost**: Quantum layers add overhead due to circuit simulation\n",
    "2. **Prediction Quality**: Results will vary based on the specific test case\n",
    "3. **Trade-offs**: Consider speed vs accuracy for your use case\n",
    "\n",
    "Key insights:\n",
    "- Quantum advantage may emerge for specific protein classes\n",
    "- Hardware quantum processors could reduce computational overhead\n",
    "- Hybrid approach allows flexibility based on requirements"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
