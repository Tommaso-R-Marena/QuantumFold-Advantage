{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”¬ Quantum Advantage Benchmark: Rigorous Scientific Validation\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Tommaso-R-Marena/QuantumFold-Advantage/blob/main/examples/02_quantum_advantage_benchmark.ipynb)\n",
    "[![GitHub](https://img.shields.io/badge/GitHub-Repo-blue)](https://github.com/Tommaso-R-Marena/QuantumFold-Advantage)\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook implements a **publication-grade benchmarking pipeline** to rigorously test whether quantum-enhanced protein folding demonstrates measurable advantages over classical methods.\n",
    "\n",
    "### Scientific Methodology\n",
    "\n",
    "We employ gold-standard statistical practices:\n",
    "- âœ… **Real CASP15 targets** (not synthetic data)\n",
    "- âœ… **Paired comparison** (quantum vs. classical on identical data)\n",
    "- âœ… **Multiple metrics** (TM-score, RMSD, GDT-TS, lDDT)\n",
    "- âœ… **Statistical rigor** (Wilcoxon test, bootstrap CI, effect sizes)\n",
    "- âœ… **Power analysis** (verify sufficient sample size)\n",
    "- âœ… **Publication-quality figures** (300 DPI)\n",
    "- âœ… **Reproducibility** (seeds, versions, checkpoints)\n",
    "- âœ… **Interactive 3D visualization** (py3Dmol)\n",
    "\n",
    "### Runtime\n",
    "â±ï¸ **30-45 minutes** on free Colab (T4 GPU)\n",
    "\n",
    "### Output\n",
    "- ðŸ“Š Comprehensive statistical analysis\n",
    "- ðŸ“ˆ Research-grade visualizations\n",
    "- ðŸ“„ LaTeX tables for papers\n",
    "- ðŸ’¾ Detailed results CSV + JSON\n",
    "- ðŸŽ¨ Interactive 3D structure viewer\n",
    "- ðŸ“¦ Complete result archive\n",
    "\n",
    "### Citation\n",
    "```bibtex\n",
    "@article{marena2024quantumfold,\n",
    "  title={Quantum-Enhanced Protein Structure Prediction},\n",
    "  author={Marena, Tommaso R.},\n",
    "  journal={In Preparation},\n",
    "  year={2024}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check runtime environment\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print('ðŸš€ Running in Google Colab')\n",
    "    !nvidia-smi -L\n",
    "    !nvidia-smi --query-gpu=memory.total,memory.free --format=csv\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        print(f'\\nâœ… CUDA {torch.version.cuda} available')\n",
    "        print(f'   Device: {torch.cuda.get_device_name(0)}')\n",
    "        print(f'   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')\n",
    "else:\n",
    "    print('ðŸ’» Running locally')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Installation & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    print('ðŸ“¥ Cloning repository...')\n",
    "    !git clone https://github.com/Tommaso-R-Marena/QuantumFold-Advantage.git\n",
    "    %cd QuantumFold-Advantage\n",
    "    \n",
    "    print('\\nðŸ“¦ Installing dependencies...')\n",
    "    !pip install -q -e '.[protein-lm]'\n",
    "    !pip install -q py3Dmol nglview biopython\n",
    "    \n",
    "    print('\\nâœ… Installation complete!')\n",
    "    print('âš ï¸  Restarting runtime to apply numpy 2.0 upgrade...')\n",
    "    print('    After restart, skip this cell and continue from imports.')\n",
    "    \n",
    "    import os\n",
    "    import time\n",
    "    time.sleep(2)\n",
    "    os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# QuantumFold modules\n",
    "from src.advanced_model import AdvancedProteinFoldingModel\n",
    "from src.protein_embeddings import ESM2Embedder\n",
    "from src.benchmarks import ResearchBenchmark, StructurePredictionMetrics\n",
    "from src.visualization import ProteinVisualizer\n",
    "from src.data.casp_loader import CASPDataLoader\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'ðŸ”§ Using device: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'   GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Log versions for reproducibility\n",
    "print(f'\\nðŸ“š Package versions:')\n",
    "print(f'   Python: {sys.version.split()[0]}')\n",
    "print(f'   NumPy: {np.__version__}')\n",
    "print(f'   PyTorch: {torch.__version__}')\n",
    "print(f'   Pandas: {pd.__version__}')\n",
    "\n",
    "print('\\nâœ… Imports complete!')\n",
    "print(f'   Timestamp: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Load CASP15 Benchmark Dataset\n",
    "\n",
    "We use real protein folding targets from CASP15 (Critical Assessment of protein Structure Prediction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ðŸ“¥ Loading CASP15 targets...')\n",
    "start_time = time.time()\n",
    "\n",
    "casp_loader = CASPDataLoader(casp_version=15, cache_dir='./data/casp15')\n",
    "\n",
    "# Get diverse set of targets (varying difficulty)\n",
    "targets = casp_loader.get_targets(\n",
    "    max_targets=10,\n",
    "    min_length=50,\n",
    "    max_length=300,\n",
    "    difficulty_range=['medium', 'hard']  # Focus on challenging targets\n",
    ")\n",
    "\n",
    "load_time = time.time() - start_time\n",
    "print(f'âœ… Loaded {len(targets)} CASP15 targets in {load_time:.2f}s')\n",
    "\n",
    "# Display target information\n",
    "print('\\nðŸ“‹ Target Summary:')\n",
    "print('â”€' * 70)\n",
    "for i, target in enumerate(targets, 1):\n",
    "    print(f\"{i:2d}. {target['id']:15s} | Length: {len(target['sequence']):3d} | Difficulty: {target['difficulty']:6s}\")\n",
    "\n",
    "# Compute statistics\n",
    "lengths = [len(t['sequence']) for t in targets]\n",
    "total_residues = sum(lengths)\n",
    "print('â”€' * 70)\n",
    "print(f'Length range: {min(lengths)}-{max(lengths)} residues')\n",
    "print(f'Mean length: {np.mean(lengths):.1f} Â± {np.std(lengths):.1f}')\n",
    "print(f'Total residues: {total_residues:,}')\n",
    "print(f'\\nðŸ’¾ Dataset size: ~{total_residues * 4 / 1024:.1f} KB (coordinates only)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§¬ Initialize Models\n",
    "\n",
    "We create **paired models** - identical architecture except for quantum enhancement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ESM-2 embedder (shared by both models)\n",
    "print('â³ Loading ESM-2 embedder (650M parameters)...')\n",
    "embed_start = time.time()\n",
    "embedder = ESM2Embedder(model_name='esm2_t33_650M_UR50D', device=device)\n",
    "embed_time = time.time() - embed_start\n",
    "print(f'âœ… ESM-2 loaded in {embed_time:.2f}s')\n",
    "\n",
    "# Model configuration\n",
    "model_config = {\n",
    "    'input_dim': 1280,\n",
    "    'c_s': 384,\n",
    "    'c_z': 128,\n",
    "    'num_encoder_layers': 8,\n",
    "    'num_structure_layers': 6,\n",
    "    'num_heads': 8,\n",
    "}\n",
    "\n",
    "print('\\nðŸ”¬ Initializing models...')\n",
    "\n",
    "# Quantum-enhanced model\n",
    "quantum_model = AdvancedProteinFoldingModel(\n",
    "    **model_config,\n",
    "    use_quantum=True,\n",
    "    num_qubits=8,\n",
    "    quantum_depth=4\n",
    ").to(device)\n",
    "\n",
    "# Classical baseline (identical except no quantum layers)\n",
    "classical_model = AdvancedProteinFoldingModel(\n",
    "    **model_config,\n",
    "    use_quantum=False\n",
    ").to(device)\n",
    "\n",
    "# Load pretrained weights if available\n",
    "quantum_checkpoint = 'outputs/quantum_model/best_model.pt'\n",
    "classical_checkpoint = 'outputs/classical_model/best_model.pt'\n",
    "\n",
    "if os.path.exists(quantum_checkpoint):\n",
    "    quantum_model.load_state_dict(torch.load(quantum_checkpoint, map_location=device))\n",
    "    print('âœ… Loaded quantum checkpoint')\n",
    "else:\n",
    "    print('âš ï¸  No quantum checkpoint found - using random initialization')\n",
    "\n",
    "if os.path.exists(classical_checkpoint):\n",
    "    classical_model.load_state_dict(torch.load(classical_checkpoint, map_location=device))\n",
    "    print('âœ… Loaded classical checkpoint')\n",
    "else:\n",
    "    print('âš ï¸  No classical checkpoint found - using random initialization')\n",
    "\n",
    "quantum_model.eval()\n",
    "classical_model.eval()\n",
    "\n",
    "# Count parameters\n",
    "quantum_params = sum(p.numel() for p in quantum_model.parameters())\n",
    "classical_params = sum(p.numel() for p in classical_model.parameters())\n",
    "param_diff = quantum_params - classical_params\n",
    "\n",
    "print(f'\\nðŸ“Š Model Statistics:')\n",
    "print(f'   Quantum model:   {quantum_params:,} parameters')\n",
    "print(f'   Classical model: {classical_params:,} parameters')\n",
    "print(f'   Difference:      {param_diff:,} (+{param_diff/classical_params*100:.1f}%)')\n",
    "\n",
    "# Memory footprint\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    print(f'\\nðŸ’¾ GPU memory cleared for benchmarking')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Run Predictions on All Targets\n",
    "\n",
    "We predict structures using both models on identical inputs with detailed timing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage for results\n",
    "results = {\n",
    "    'target_id': [],\n",
    "    'sequence_length': [],\n",
    "    'difficulty': [],\n",
    "    'quantum': {'coords': [], 'confidence': [], 'time': [], 'memory_mb': []},\n",
    "    'classical': {'coords': [], 'confidence': [], 'time': [], 'memory_mb': []},\n",
    "    'true_coords': []\n",
    "}\n",
    "\n",
    "print('ðŸš€ Running predictions...')\n",
    "print('â”€' * 80)\n",
    "overall_start = time.time()\n",
    "\n",
    "for idx, target in enumerate(tqdm(targets, desc='Targets'), 1):\n",
    "    target_id = target['id']\n",
    "    sequence = target['sequence']\n",
    "    true_coords = target['coordinates']  # CA coordinates\n",
    "    \n",
    "    # Get embeddings (shared)\n",
    "    with torch.no_grad():\n",
    "        embeddings = embedder([sequence])\n",
    "        emb_tensor = embeddings['embeddings'].to(device)\n",
    "    \n",
    "    # Quantum prediction with timing and memory tracking\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        quantum_output = quantum_model(emb_tensor)\n",
    "    quantum_time = time.time() - start_time\n",
    "    \n",
    "    quantum_memory = torch.cuda.max_memory_allocated() / 1024**2 if torch.cuda.is_available() else 0\n",
    "    \n",
    "    # Classical prediction with timing and memory tracking\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        classical_output = classical_model(emb_tensor)\n",
    "    classical_time = time.time() - start_time\n",
    "    \n",
    "    classical_memory = torch.cuda.max_memory_allocated() / 1024**2 if torch.cuda.is_available() else 0\n",
    "    \n",
    "    # Store results\n",
    "    results['target_id'].append(target_id)\n",
    "    results['sequence_length'].append(len(sequence))\n",
    "    results['difficulty'].append(target['difficulty'])\n",
    "    results['true_coords'].append(true_coords)\n",
    "    \n",
    "    results['quantum']['coords'].append(quantum_output['coordinates'].cpu().numpy()[0])\n",
    "    results['quantum']['confidence'].append(quantum_output['plddt'].cpu().numpy()[0])\n",
    "    results['quantum']['time'].append(quantum_time)\n",
    "    results['quantum']['memory_mb'].append(quantum_memory)\n",
    "    \n",
    "    results['classical']['coords'].append(classical_output['coordinates'].cpu().numpy()[0])\n",
    "    results['classical']['confidence'].append(classical_output['plddt'].cpu().numpy()[0])\n",
    "    results['classical']['time'].append(classical_time)\n",
    "    results['classical']['memory_mb'].append(classical_memory)\n",
    "\n",
    "overall_time = time.time() - overall_start\n",
    "\n",
    "print('\\nâœ… Predictions complete!')\n",
    "print('â”€' * 80)\n",
    "print(f'Total time: {overall_time:.2f}s ({overall_time/60:.1f} min)')\n",
    "print(f'\\nâ±ï¸  Average inference time:')\n",
    "print(f'   Quantum:   {np.mean(results[\"quantum\"][\"time\"]):.3f}s Â± {np.std(results[\"quantum\"][\"time\"]):.3f}s')\n",
    "print(f'   Classical: {np.mean(results[\"classical\"][\"time\"]):.3f}s Â± {np.std(results[\"classical\"][\"time\"]):.3f}s')\n",
    "print(f'   Speedup:   {np.mean(results[\"classical\"][\"time\"]) / np.mean(results[\"quantum\"][\"time\"]):.2f}x')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f'\\nðŸ’¾ Average peak memory:')\n",
    "    print(f'   Quantum:   {np.mean(results[\"quantum\"][\"memory_mb\"]):.1f} MB')\n",
    "    print(f'   Classical: {np.mean(results[\"classical\"][\"memory_mb\"]):.1f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Compute Structural Metrics\n",
    "\n",
    "Calculate comprehensive metrics for each prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize benchmark\n",
    "benchmark = ResearchBenchmark(alpha=0.05, n_bootstrap=10000)\n",
    "\n",
    "# Compute metrics for all targets\n",
    "metrics_data = {\n",
    "    'quantum': [],\n",
    "    'classical': []\n",
    "}\n",
    "\n",
    "print('ðŸ”¬ Computing structural metrics...')\n",
    "\n",
    "for i in tqdm(range(len(results['target_id'])), desc='Metrics'):\n",
    "    target_id = results['target_id'][i]\n",
    "    true_coords = results['true_coords'][i]\n",
    "    sequence = targets[i]['sequence']\n",
    "    \n",
    "    # Quantum metrics\n",
    "    quantum_coords = results['quantum']['coords'][i]\n",
    "    quantum_conf = results['quantum']['confidence'][i]\n",
    "    quantum_metrics = benchmark.compute_all_metrics(\n",
    "        quantum_coords, true_coords, sequence, quantum_conf\n",
    "    )\n",
    "    metrics_data['quantum'].append(quantum_metrics)\n",
    "    \n",
    "    # Classical metrics\n",
    "    classical_coords = results['classical']['coords'][i]\n",
    "    classical_conf = results['classical']['confidence'][i]\n",
    "    classical_metrics = benchmark.compute_all_metrics(\n",
    "        classical_coords, true_coords, sequence, classical_conf\n",
    "    )\n",
    "    metrics_data['classical'].append(classical_metrics)\n",
    "\n",
    "print('\\nâœ… Metrics computed!')\n",
    "\n",
    "# Create summary DataFrame\n",
    "summary_rows = []\n",
    "for i, target_id in enumerate(results['target_id']):\n",
    "    row = {\n",
    "        'Target': target_id,\n",
    "        'Length': results['sequence_length'][i],\n",
    "        'Difficulty': results['difficulty'][i],\n",
    "    }\n",
    "    # Add quantum metrics\n",
    "    for key, val in metrics_data['quantum'][i].to_dict().items():\n",
    "        row[f'Q_{key}'] = val\n",
    "    # Add classical metrics\n",
    "    for key, val in metrics_data['classical'][i].to_dict().items():\n",
    "        row[f'C_{key}'] = val\n",
    "    \n",
    "    # Add timing and memory\n",
    "    row['Q_Time (s)'] = results['quantum']['time'][i]\n",
    "    row['C_Time (s)'] = results['classical']['time'][i]\n",
    "    if torch.cuda.is_available():\n",
    "        row['Q_Memory (MB)'] = results['quantum']['memory_mb'][i]\n",
    "        row['C_Memory (MB)'] = results['classical']['memory_mb'][i]\n",
    "    \n",
    "    summary_rows.append(row)\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "\n",
    "print('\\nðŸ“Š Per-Target Summary:')\n",
    "display_cols = ['Target', 'Length', 'Q_TM-score', 'C_TM-score', 'Q_RMSD (Ã…)', 'C_RMSD (Ã…)']\n",
    "display(summary_df[display_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¬ Statistical Analysis\n",
    "\n",
    "Rigorous hypothesis testing to determine if quantum model shows significant improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract metric arrays\n",
    "quantum_tm = np.array([m.tm_score for m in metrics_data['quantum']])\n",
    "classical_tm = np.array([m.tm_score for m in metrics_data['classical']])\n",
    "\n",
    "quantum_rmsd = np.array([m.rmsd for m in metrics_data['quantum']])\n",
    "classical_rmsd = np.array([m.rmsd for m in metrics_data['classical']])\n",
    "\n",
    "quantum_gdt = np.array([m.gdt_ts for m in metrics_data['quantum']])\n",
    "classical_gdt = np.array([m.gdt_ts for m in metrics_data['classical']])\n",
    "\n",
    "quantum_lddt = np.array([m.lddt for m in metrics_data['quantum']])\n",
    "classical_lddt = np.array([m.lddt for m in metrics_data['classical']])\n",
    "\n",
    "# Perform statistical comparisons\n",
    "print('ðŸ“ˆ Statistical Analysis')\n",
    "print('=' * 80)\n",
    "\n",
    "# TM-score comparison\n",
    "tm_results = benchmark.compare_methods(\n",
    "    quantum_tm, classical_tm,\n",
    "    metric_name='TM-score',\n",
    "    higher_is_better=True\n",
    ")\n",
    "\n",
    "print('\\n1. TM-SCORE COMPARISON')\n",
    "print('-' * 80)\n",
    "print(f'Quantum:   {tm_results[\"quantum_mean\"]:.4f} Â± {tm_results[\"quantum_std\"]:.4f}')\n",
    "print(f'Classical: {tm_results[\"classical_mean\"]:.4f} Â± {tm_results[\"classical_std\"]:.4f}')\n",
    "print(f'Difference: {tm_results[\"quantum_mean\"] - tm_results[\"classical_mean\"]:.4f}')\n",
    "print(f'95% CI (difference): [{tm_results[\"difference_ci\"][0]:.4f}, {tm_results[\"difference_ci\"][1]:.4f}]')\n",
    "print(f'\\nWilcoxon p-value: {tm_results[\"wilcoxon_pvalue\"]:.6f}')\n",
    "print(f\"Cohen's d: {tm_results[\"cohens_d\"]:.3f}\")\n",
    "print(f'Statistical Power: {tm_results[\"power\"]:.3f}')\n",
    "print(f'Significant at Î±=0.05: {\"YES âœ…\" if tm_results[\"significant\"] else \"NO âŒ\"}')\n",
    "\n",
    "# RMSD comparison (lower is better)\n",
    "rmsd_results = benchmark.compare_methods(\n",
    "    quantum_rmsd, classical_rmsd,\n",
    "    metric_name='RMSD',\n",
    "    higher_is_better=False\n",
    ")\n",
    "\n",
    "print('\\n2. RMSD COMPARISON')\n",
    "print('-' * 80)\n",
    "print(f'Quantum:   {rmsd_results[\"quantum_mean\"]:.4f} Â± {rmsd_results[\"quantum_std\"]:.4f} Ã…')\n",
    "print(f'Classical: {rmsd_results[\"classical_mean\"]:.4f} Â± {rmsd_results[\"classical_std\"]:.4f} Ã…')\n",
    "print(f'Difference: {rmsd_results[\"quantum_mean\"] - rmsd_results[\"classical_mean\"]:.4f} Ã…')\n",
    "print(f'Wilcoxon p-value: {rmsd_results[\"wilcoxon_pvalue\"]:.6f}')\n",
    "print(f\"Cohen's d: {rmsd_results[\"cohens_d\"]:.3f}\")\n",
    "print(f'Significant: {\"YES âœ…\" if rmsd_results[\"significant\"] else \"NO âŒ\"}')\n",
    "\n",
    "# GDT-TS comparison\n",
    "gdt_results = benchmark.compare_methods(\n",
    "    quantum_gdt, classical_gdt,\n",
    "    metric_name='GDT-TS',\n",
    "    higher_is_better=True\n",
    ")\n",
    "\n",
    "print('\\n3. GDT-TS COMPARISON')\n",
    "print('-' * 80)\n",
    "print(f'Quantum:   {gdt_results[\"quantum_mean\"]:.2f} Â± {gdt_results[\"quantum_std\"]:.2f}')\n",
    "print(f'Classical: {gdt_results[\"classical_mean\"]:.2f} Â± {gdt_results[\"classical_std\"]:.2f}')\n",
    "print(f'Wilcoxon p-value: {gdt_results[\"wilcoxon_pvalue\"]:.6f}')\n",
    "print(f'Significant: {\"YES âœ…\" if gdt_results[\"significant\"] else \"NO âŒ\"}')\n",
    "\n",
    "print('\\n' + '=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Publication-Quality Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TM-score comparison plot\n",
    "fig = benchmark.plot_comparison(\n",
    "    quantum_tm, classical_tm,\n",
    "    metric_name='TM-score',\n",
    "    figsize=(16, 5)\n",
    ")\n",
    "plt.savefig('tm_score_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# RMSD comparison plot\n",
    "fig = benchmark.plot_comparison(\n",
    "    quantum_rmsd, classical_rmsd,\n",
    "    metric_name='RMSD (Ã…)',\n",
    "    figsize=(16, 5)\n",
    ")\n",
    "plt.savefig('rmsd_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-metric radar plot\n",
    "from math import pi\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
    "\n",
    "metrics = ['TM-score', 'GDT-TS', 'lDDT', 'Contact\\nPrecision']\n",
    "quantum_vals = [\n",
    "    np.mean(quantum_tm),\n",
    "    np.mean(quantum_gdt) / 100,  # Normalize to 0-1\n",
    "    np.mean(quantum_lddt) / 100,\n",
    "    np.mean([m.contact_precision for m in metrics_data['quantum']])\n",
    "]\n",
    "classical_vals = [\n",
    "    np.mean(classical_tm),\n",
    "    np.mean(classical_gdt) / 100,\n",
    "    np.mean(classical_lddt) / 100,\n",
    "    np.mean([m.contact_precision for m in metrics_data['classical']])\n",
    "]\n",
    "\n",
    "angles = [n / len(metrics) * 2 * pi for n in range(len(metrics))]\n",
    "quantum_vals += quantum_vals[:1]\n",
    "classical_vals += classical_vals[:1]\n",
    "angles += angles[:1]\n",
    "\n",
    "ax.plot(angles, quantum_vals, 'o-', linewidth=2, label='Quantum', color='#FF6B6B')\n",
    "ax.fill(angles, quantum_vals, alpha=0.25, color='#FF6B6B')\n",
    "ax.plot(angles, classical_vals, 'o-', linewidth=2, label='Classical', color='#4ECDC4')\n",
    "ax.fill(angles, classical_vals, alpha=0.25, color='#4ECDC4')\n",
    "\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(metrics, size=12)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title('Multi-Metric Performance Comparison', size=16, fontweight='bold', pad=20)\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=12)\n",
    "ax.grid(True)\n",
    "\n",
    "plt.savefig('radar_plot.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¨ Interactive 3D Structure Visualization\n",
    "\n",
    "Visualize best and worst predictions using py3Dmol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import py3Dmol\n",
    "    \n",
    "    # Find best and worst quantum predictions by TM-score\n",
    "    best_idx = np.argmax(quantum_tm)\n",
    "    worst_idx = np.argmin(quantum_tm)\n",
    "    \n",
    "    print(f'ðŸ† Best prediction: {results[\"target_id\"][best_idx]} (TM-score: {quantum_tm[best_idx]:.3f})')\n",
    "    print(f'âš ï¸  Worst prediction: {results[\"target_id\"][worst_idx]} (TM-score: {quantum_tm[worst_idx]:.3f})')\n",
    "    \n",
    "    def visualize_structure(coords, title, color='spectrum'):\n",
    "        \"\"\"Create 3D visualization of protein structure.\"\"\"\n",
    "        view = py3Dmol.view(width=800, height=600)\n",
    "        \n",
    "        # Convert coordinates to PDB format\n",
    "        pdb_lines = [\"MODEL 1\"]\n",
    "        for i, (x, y, z) in enumerate(coords, 1):\n",
    "            pdb_lines.append(\n",
    "                f\"ATOM  {i:5d}  CA  ALA A{i:4d}    \"\n",
    "                f\"{x:8.3f}{y:8.3f}{z:8.3f}  1.00  0.00           C\"\n",
    "            )\n",
    "        pdb_lines.append(\"ENDMDL\")\n",
    "        pdb_str = \"\\n\".join(pdb_lines)\n",
    "        \n",
    "        view.addModel(pdb_str, 'pdb')\n",
    "        view.setStyle({'cartoon': {'color': color}})\n",
    "        view.zoomTo()\n",
    "        \n",
    "        return view\n",
    "    \n",
    "    print(f'\\nðŸŽ¨ Visualizing best prediction...')\n",
    "    best_coords = results['quantum']['coords'][best_idx]\n",
    "    view = visualize_structure(best_coords, f\"Best: {results['target_id'][best_idx]}\")\n",
    "    view.show()\n",
    "    \n",
    "except ImportError:\n",
    "    print('âš ï¸  py3Dmol not available. Skipping 3D visualization.')\n",
    "    print('   Install with: pip install py3Dmol')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“„ Generate LaTeX Tables for Publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate LaTeX table\n",
    "latex_table = benchmark.generate_latex_table(\n",
    "    tm_results,\n",
    "    caption='Quantum vs. Classical TM-score Comparison on CASP15 Targets'\n",
    ")\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('LaTeX Table (copy to your paper):')\n",
    "print('=' * 80)\n",
    "print(latex_table)\n",
    "print('=' * 80)\n",
    "\n",
    "# Save to file\n",
    "with open('results_table.tex', 'w') as f:\n",
    "    f.write(latex_table)\n",
    "print('\\nâœ… Saved to results_table.tex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Save Complete Results & Create Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Save detailed results\n",
    "summary_df.to_csv('benchmark_results.csv', index=False)\n",
    "print('âœ… Saved benchmark_results.csv')\n",
    "\n",
    "# Save statistical results\n",
    "stats_summary = {\n",
    "    'TM-score': tm_results,\n",
    "    'RMSD': rmsd_results,\n",
    "    'GDT-TS': gdt_results\n",
    "}\n",
    "\n",
    "with open('statistical_results.json', 'w') as f:\n",
    "    # Convert numpy types to Python types for JSON\n",
    "    json_safe = {}\n",
    "    for metric, results_dict in stats_summary.items():\n",
    "        json_safe[metric] = {k: float(v) if isinstance(v, (np.floating, np.integer)) else v \n",
    "                             for k, v in results_dict.items() if k not in ['quantum_ci', 'classical_ci', 'difference_ci']}\n",
    "    json.dump(json_safe, f, indent=2)\n",
    "\n",
    "print('âœ… Saved statistical_results.json')\n",
    "\n",
    "# Create comprehensive results archive\n",
    "print('\\nðŸ“¦ Creating results archive...')\n",
    "archive_name = f'quantumfold_benchmark_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.zip'\n",
    "\n",
    "with zipfile.ZipFile(archive_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    # Add CSV and JSON results\n",
    "    zipf.write('benchmark_results.csv')\n",
    "    zipf.write('statistical_results.json')\n",
    "    zipf.write('results_table.tex')\n",
    "    \n",
    "    # Add visualizations\n",
    "    for img in ['tm_score_comparison.png', 'rmsd_comparison.png', 'radar_plot.png']:\n",
    "        if Path(img).exists():\n",
    "            zipf.write(img)\n",
    "    \n",
    "    # Add metadata\n",
    "    metadata = {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'num_targets': len(targets),\n",
    "        'seed': SEED,\n",
    "        'device': str(device),\n",
    "        'pytorch_version': torch.__version__,\n",
    "        'numpy_version': np.__version__,\n",
    "        'quantum_params': quantum_params,\n",
    "        'classical_params': classical_params\n",
    "    }\n",
    "    zipf.writestr('metadata.json', json.dumps(metadata, indent=2))\n",
    "\n",
    "print(f'âœ… Created archive: {archive_name}')\n",
    "print(f'   Size: {Path(archive_name).stat().st_size / 1024:.1f} KB')\n",
    "\n",
    "# Download in Colab\n",
    "if IN_COLAB:\n",
    "    print('\\nðŸ“¥ Downloading files...')\n",
    "    from google.colab import files\n",
    "    files.download(archive_name)\n",
    "    print('âœ… Download complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ Summary & Interpretation\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "Based on the statistical analysis above:\n",
    "\n",
    "1. **TM-score**: Quantum model shows [FILL BASED ON RESULTS]\n",
    "2. **RMSD**: [FILL BASED ON RESULTS]\n",
    "3. **GDT-TS**: [FILL BASED ON RESULTS]\n",
    "\n",
    "### Statistical Significance\n",
    "\n",
    "- Wilcoxon signed-rank test p-value: [FILL]\n",
    "- Effect size (Cohen's d): [FILL]\n",
    "- Statistical power: [FILL]\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "[FILL WITH SCIENTIFIC INTERPRETATION]\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Expand to full CASP15 dataset\n",
    "- Test on CASP16 targets (when available)\n",
    "- Conduct ablation studies on quantum components\n",
    "- Optimize hyperparameters\n",
    "- Scale to larger proteins (>500 residues)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
