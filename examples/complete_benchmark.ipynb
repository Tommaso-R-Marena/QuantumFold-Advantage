{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QuantumFold-Advantage: Complete Benchmarking Suite\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Tommaso-R-Marena/QuantumFold-Advantage/blob/main/examples/complete_benchmark.ipynb)\n",
    "\n",
    "**This notebook runs EVERYTHING:**\n",
    "- Full training pipeline (quantum vs classical)\n",
    "- Comprehensive evaluation metrics\n",
    "- Statistical validation with hypothesis testing\n",
    "- Publication-ready visualizations\n",
    "- Ablation studies\n",
    "\n",
    "**Estimated runtime:** 30-60 minutes with GPU\n",
    "\n",
    "**Author:** Tommaso R. Marena (The Catholic University of America)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "print(f'CUDA available: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB')\n",
    "else:\n",
    "    print('WARNING: No GPU detected. Training will be slow.')\n",
    "\n",
    "# Mount Google Drive (optional, for saving results)\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    SAVE_TO_DRIVE = True\n",
    "    print('Google Drive mounted successfully!')\n",
    "except:\n",
    "    SAVE_TO_DRIVE = False\n",
    "    print('Running without Google Drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/Tommaso-R-Marena/QuantumFold-Advantage.git\n",
    "import os\n",
    "os.chdir('QuantumFold-Advantage')\n",
    "print('Repository cloned successfully!')\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install core dependencies\n",
    "print('Installing core dependencies...')\n",
    "!pip install -q torch pennylane pennylane-lightning\n",
    "!pip install -q numpy scipy pandas matplotlib seaborn plotly\n",
    "!pip install -q scikit-learn statsmodels biopython\n",
    "!pip install -q tqdm pyyaml\n",
    "\n",
    "# Install ESM-2 (optional but recommended)\n",
    "print('\\nInstalling ESM-2...')\n",
    "!pip install -q fair-esm transformers\n",
    "\n",
    "print('\\nAll dependencies installed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment configuration\n",
    "import sys\n",
    "sys.path.insert(0, '/content/QuantumFold-Advantage')\n",
    "\n",
    "CONFIG = {\n",
    "    # Data\n",
    "    'train_samples': 200,  # Increase for better results\n",
    "    'val_samples': 50,\n",
    "    'test_samples': 50,\n",
    "    'seq_len': 64,\n",
    "    \n",
    "    # Training\n",
    "    'epochs': 20,  # Increase to 50-100 for publication\n",
    "    'batch_size': 16,\n",
    "    'learning_rate': 1e-3,\n",
    "    'warmup_epochs': 2,\n",
    "    \n",
    "    # Model\n",
    "    'hidden_dim': 256,\n",
    "    'pair_dim': 64,\n",
    "    'n_structure_layers': 4,\n",
    "    \n",
    "    # Quantum\n",
    "    'n_qubits': 6,\n",
    "    'quantum_depth': 3,\n",
    "    \n",
    "    # Validation\n",
    "    'alpha': 0.05,\n",
    "    'n_bootstrap': 5000,\n",
    "    \n",
    "    # Output\n",
    "    'output_dir': '/content/outputs',\n",
    "    'save_to_drive': SAVE_TO_DRIVE\n",
    "}\n",
    "\n",
    "print('Configuration:')\n",
    "for key, value in CONFIG.items():\n",
    "    print(f'  {key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, n_samples, seq_len, seed=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        self.n_samples = n_samples\n",
    "        self.seq_len = seq_len\n",
    "        self.amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "        \n",
    "        # Generate synthetic protein structures\n",
    "        self.sequences = []\n",
    "        self.coordinates = []\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            # Random sequence\n",
    "            seq = ''.join(np.random.choice(list(self.amino_acids), size=seq_len))\n",
    "            self.sequences.append(seq)\n",
    "            \n",
    "            # Alpha helix coordinates with noise\n",
    "            t = np.linspace(0, 4*np.pi, seq_len)\n",
    "            coords = np.zeros((seq_len, 3))\n",
    "            coords[:, 0] = 2.3 * np.cos(t) + np.random.randn(seq_len) * 0.3\n",
    "            coords[:, 1] = 2.3 * np.sin(t) + np.random.randn(seq_len) * 0.3\n",
    "            coords[:, 2] = 1.5 * t + np.random.randn(seq_len) * 0.3\n",
    "            self.coordinates.append(coords)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'sequence': self.sequences[idx],\n",
    "            'coordinates': torch.tensor(self.coordinates[idx], dtype=torch.float32)\n",
    "        }\n",
    "\n",
    "# Create datasets\n",
    "print('Creating datasets...')\n",
    "train_dataset = ProteinDataset(CONFIG['train_samples'], CONFIG['seq_len'], seed=42)\n",
    "val_dataset = ProteinDataset(CONFIG['val_samples'], CONFIG['seq_len'], seed=123)\n",
    "test_dataset = ProteinDataset(CONFIG['test_samples'], CONFIG['seq_len'], seed=456)\n",
    "\n",
    "print(f'Train: {len(train_dataset)} samples')\n",
    "print(f'Val: {len(val_dataset)} samples')\n",
    "print(f'Test: {len(test_dataset)} samples')\n",
    "print(f'Sequence length: {CONFIG[\"seq_len\"]} residues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training\n",
    "\n",
    "### 4.1 Train Quantum-Enhanced Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.advanced_model import AdvancedProteinFoldingModel\n",
    "from src.advanced_training import AdvancedTrainer, TrainingConfig\n",
    "from src.protein_embeddings import ESM2Embedder\n",
    "from functools import partial\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger('QuantumFold')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Load ESM-2 embedder (smaller model for Colab)\n",
    "print('\\nLoading ESM-2 embedder...')\n",
    "embedder = ESM2Embedder(model_name='esm2_t12_35M_UR50D', freeze=True).to(device)\n",
    "print(f'Embedding dimension: {embedder.embed_dim}')\n",
    "\n",
    "# Collate function\n",
    "def collate_fn(batch, embedder):\n",
    "    sequences = [item['sequence'] for item in batch]\n",
    "    coordinates = torch.stack([item['coordinates'] for item in batch])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        embeddings_dict = embedder(sequences)\n",
    "        embeddings = embeddings_dict['embeddings']\n",
    "    \n",
    "    return {\n",
    "        'sequence': embeddings,\n",
    "        'coordinates': coordinates,\n",
    "        'mask': torch.ones(len(batch), embeddings.shape[1], dtype=torch.bool)\n",
    "    }\n",
    "\n",
    "collate_with_emb = partial(collate_fn, embedder=embedder)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], \n",
    "                         shuffle=True, collate_fn=collate_with_emb)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], \n",
    "                       shuffle=False, collate_fn=collate_with_emb)\n",
    "\n",
    "print('\\nDataloaders created successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize quantum model\n",
    "print('\\n' + '='*80)\n",
    "print('TRAINING QUANTUM-ENHANCED MODEL')\n",
    "print('='*80)\n",
    "\n",
    "quantum_model = AdvancedProteinFoldingModel(\n",
    "    input_dim=embedder.embed_dim,\n",
    "    c_s=CONFIG['hidden_dim'],\n",
    "    c_z=CONFIG['pair_dim'],\n",
    "    n_structure_layers=CONFIG['n_structure_layers'],\n",
    "    use_quantum=True\n",
    ")\n",
    "\n",
    "n_params = sum(p.numel() for p in quantum_model.parameters() if p.requires_grad)\n",
    "print(f'Model parameters: {n_params:,}')\n",
    "\n",
    "# Training configuration\n",
    "quantum_config = TrainingConfig(\n",
    "    epochs=CONFIG['epochs'],\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    learning_rate=CONFIG['learning_rate'],\n",
    "    warmup_epochs=CONFIG['warmup_epochs'],\n",
    "    use_amp=True,\n",
    "    use_ema=True,\n",
    "    checkpoint_dir=f\"{CONFIG['output_dir']}/quantum_checkpoints\"\n",
    ")\n",
    "\n",
    "# Train\n",
    "quantum_trainer = AdvancedTrainer(quantum_model, quantum_config, device, logger)\n",
    "quantum_history = quantum_trainer.train(train_loader, val_loader)\n",
    "\n",
    "print('\\nQuantum model training complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Train Classical Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize classical model\n",
    "print('\\n' + '='*80)\n",
    "print('TRAINING CLASSICAL BASELINE MODEL')\n",
    "print('='*80)\n",
    "\n",
    "classical_model = AdvancedProteinFoldingModel(\n",
    "    input_dim=embedder.embed_dim,\n",
    "    c_s=CONFIG['hidden_dim'],\n",
    "    c_z=CONFIG['pair_dim'],\n",
    "    n_structure_layers=CONFIG['n_structure_layers'],\n",
    "    use_quantum=False  # Classical baseline\n",
    ")\n",
    "\n",
    "n_params_classical = sum(p.numel() for p in classical_model.parameters() if p.requires_grad)\n",
    "print(f'Model parameters: {n_params_classical:,}')\n",
    "print(f'Parameter reduction: {(1 - n_params/n_params_classical)*100:.1f}%')\n",
    "\n",
    "# Training configuration\n",
    "classical_config = TrainingConfig(\n",
    "    epochs=CONFIG['epochs'],\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    learning_rate=CONFIG['learning_rate'],\n",
    "    warmup_epochs=CONFIG['warmup_epochs'],\n",
    "    use_amp=True,\n",
    "    use_ema=True,\n",
    "    checkpoint_dir=f\"{CONFIG['output_dir']}/classical_checkpoints\"\n",
    ")\n",
    "\n",
    "# Train\n",
    "classical_trainer = AdvancedTrainer(classical_model, classical_config, device, logger)\n",
    "classical_history = classical_trainer.train(train_loader, val_loader)\n",
    "\n",
    "print('\\nClassical model training complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comprehensive Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.benchmarks import ProteinStructureEvaluator\n",
    "from tqdm import tqdm\n",
    "\n",
    "evaluator = ProteinStructureEvaluator()\n",
    "test_loader = DataLoader(test_dataset, batch_size=CONFIG['batch_size'], \n",
    "                        shuffle=False, collate_fn=collate_with_emb)\n",
    "\n",
    "def evaluate_model(model, loader, name):\n",
    "    model.eval()\n",
    "    \n",
    "    all_tm_scores = []\n",
    "    all_rmsd = []\n",
    "    all_gdt_ts = []\n",
    "    all_plddt = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=f'Evaluating {name}'):\n",
    "            inputs = batch['sequence'].to(device)\n",
    "            coords_true = batch['coordinates'].to(device)\n",
    "            \n",
    "            # Predict\n",
    "            outputs = model(inputs)\n",
    "            coords_pred = outputs['coordinates']\n",
    "            plddt = outputs['plddt']\n",
    "            \n",
    "            # Move to CPU\n",
    "            coords_pred_np = coords_pred.cpu().numpy()\n",
    "            coords_true_np = coords_true.cpu().numpy()\n",
    "            plddt_np = plddt.cpu().numpy()\n",
    "            \n",
    "            # Calculate metrics\n",
    "            for i in range(len(coords_pred_np)):\n",
    "                tm = evaluator.calculate_tm_score(coords_pred_np[i], coords_true_np[i])\n",
    "                rmsd = evaluator.calculate_rmsd(coords_pred_np[i], coords_true_np[i])\n",
    "                gdt = evaluator.calculate_gdt_ts(coords_pred_np[i], coords_true_np[i])\n",
    "                \n",
    "                all_tm_scores.append(tm)\n",
    "                all_rmsd.append(rmsd)\n",
    "                all_gdt_ts.append(gdt)\n",
    "                all_plddt.append(plddt_np[i].mean())\n",
    "    \n",
    "    return {\n",
    "        'tm_score': np.array(all_tm_scores),\n",
    "        'rmsd': np.array(all_rmsd),\n",
    "        'gdt_ts': np.array(all_gdt_ts),\n",
    "        'plddt': np.array(all_plddt)\n",
    "    }\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('EVALUATION ON TEST SET')\n",
    "print('='*80)\n",
    "\n",
    "quantum_results = evaluate_model(quantum_model, test_loader, 'Quantum')\n",
    "classical_results = evaluate_model(classical_model, test_loader, 'Classical')\n",
    "\n",
    "print('\\nResults Summary:')\n",
    "print('\\nQuantum Model:')\n",
    "for metric, values in quantum_results.items():\n",
    "    print(f'  {metric}: {values.mean():.4f} ± {values.std():.4f}')\n",
    "\n",
    "print('\\nClassical Model:')\n",
    "for metric, values in classical_results.items():\n",
    "    print(f'  {metric}: {values.mean():.4f} ± {values.std():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Statistical Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.statistical_validation import ComprehensiveBenchmark\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('STATISTICAL VALIDATION')\n",
    "print('='*80)\n",
    "\n",
    "benchmark = ComprehensiveBenchmark(\n",
    "    output_dir=f\"{CONFIG['output_dir']}/validation\",\n",
    "    alpha=CONFIG['alpha']\n",
    ")\n",
    "\n",
    "# TM-score comparison\n",
    "print('\\n### TM-Score Analysis ###')\n",
    "tm_comparison = benchmark.compare_methods(\n",
    "    quantum_scores=quantum_results['tm_score'],\n",
    "    classical_scores=classical_results['tm_score'],\n",
    "    metric_name='TM-score',\n",
    "    higher_is_better=True\n",
    ")\n",
    "\n",
    "# RMSD comparison\n",
    "print('\\n### RMSD Analysis ###')\n",
    "rmsd_comparison = benchmark.compare_methods(\n",
    "    quantum_scores=quantum_results['rmsd'],\n",
    "    classical_scores=classical_results['rmsd'],\n",
    "    metric_name='RMSD',\n",
    "    higher_is_better=False\n",
    ")\n",
    "\n",
    "# Generate visualizations\n",
    "benchmark.plot_comparison(\n",
    "    quantum_results['tm_score'],\n",
    "    classical_results['tm_score'],\n",
    "    metric_name='TM-score'\n",
    ")\n",
    "\n",
    "benchmark.plot_comparison(\n",
    "    quantum_results['rmsd'],\n",
    "    classical_results['rmsd'],\n",
    "    metric_name='RMSD'\n",
    ")\n",
    "\n",
    "# Save results\n",
    "benchmark.save_results()\n",
    "benchmark.generate_report()\n",
    "\n",
    "print('\\nStatistical validation complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Training curves\n",
    "ax = axes[0, 0]\n",
    "ax.plot(quantum_history['train_loss'], label='Quantum Train', linewidth=2)\n",
    "ax.plot(quantum_history['val_loss'], label='Quantum Val', linewidth=2, linestyle='--')\n",
    "ax.plot(classical_history['train_loss'], label='Classical Train', linewidth=2)\n",
    "ax.plot(classical_history['val_loss'], label='Classical Val', linewidth=2, linestyle='--')\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Loss', fontsize=12)\n",
    "ax.set_title('Training Curves', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# 2. TM-score distribution\n",
    "ax = axes[0, 1]\n",
    "ax.hist(quantum_results['tm_score'], bins=20, alpha=0.6, label='Quantum', color='blue')\n",
    "ax.hist(classical_results['tm_score'], bins=20, alpha=0.6, label='Classical', color='orange')\n",
    "ax.set_xlabel('TM-score', fontsize=12)\n",
    "ax.set_ylabel('Frequency', fontsize=12)\n",
    "ax.set_title('TM-score Distribution', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# 3. RMSD distribution\n",
    "ax = axes[1, 0]\n",
    "ax.hist(quantum_results['rmsd'], bins=20, alpha=0.6, label='Quantum', color='blue')\n",
    "ax.hist(classical_results['rmsd'], bins=20, alpha=0.6, label='Classical', color='orange')\n",
    "ax.set_xlabel('RMSD (Å)', fontsize=12)\n",
    "ax.set_ylabel('Frequency', fontsize=12)\n",
    "ax.set_title('RMSD Distribution', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# 4. Scatter plot\n",
    "ax = axes[1, 1]\n",
    "ax.scatter(classical_results['tm_score'], quantum_results['tm_score'], alpha=0.6, s=100)\n",
    "lim = [0, 1]\n",
    "ax.plot(lim, lim, 'r--', linewidth=2, label='Equal performance')\n",
    "ax.set_xlabel('Classical TM-score', fontsize=12)\n",
    "ax.set_ylabel('Quantum TM-score', fontsize=12)\n",
    "ax.set_title('Paired Comparison', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{CONFIG['output_dir']}/summary_plots.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\nVisualization complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Save all results\n",
    "results_summary = {\n",
    "    'config': CONFIG,\n",
    "    'quantum_metrics': {k: v.tolist() for k, v in quantum_results.items()},\n",
    "    'classical_metrics': {k: v.tolist() for k, v in classical_results.items()},\n",
    "    'statistical_tests': {\n",
    "        'tm_score': tm_comparison,\n",
    "        'rmsd': rmsd_comparison\n",
    "    }\n",
    "}\n",
    "\n",
    "output_path = Path(CONFIG['output_dir']) / 'complete_results.json'\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2, default=str)\n",
    "\n",
    "print(f'Results saved to {output_path}')\n",
    "\n",
    "# Copy to Google Drive if mounted\n",
    "if CONFIG['save_to_drive']:\n",
    "    !mkdir -p /content/drive/MyDrive/QuantumFold_Results\n",
    "    !cp -r {CONFIG['output_dir']}/* /content/drive/MyDrive/QuantumFold_Results/\n",
    "    print('Results copied to Google Drive!')\n",
    "\n",
    "# Create downloadable archive\n",
    "!tar -czf results.tar.gz -C {CONFIG['output_dir']} .\n",
    "print('\\nCreated results.tar.gz for download')\n",
    "\n",
    "from google.colab import files\n",
    "try:\n",
    "    files.download('results.tar.gz')\n",
    "except:\n",
    "    print('Download manually from files panel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*80)\n",
    "print('COMPLETE BENCHMARK SUMMARY')\n",
    "print('='*80)\n",
    "\n",
    "print(f'\\nDataset: {CONFIG[\"train_samples\"]} train, {CONFIG[\"val_samples\"]} val, {CONFIG[\"test_samples\"]} test')\n",
    "print(f'Training epochs: {CONFIG[\"epochs\"]}')\n",
    "print(f'Model parameters: {n_params:,} (quantum), {n_params_classical:,} (classical)')\n",
    "\n",
    "print('\\nPerformance Metrics:')\n",
    "print('\\nQuantum Model:')\n",
    "for metric in ['tm_score', 'rmsd', 'gdt_ts', 'plddt']:\n",
    "    mean = quantum_results[metric].mean()\n",
    "    std = quantum_results[metric].std()\n",
    "    print(f'  {metric.upper()}: {mean:.4f} ± {std:.4f}')\n",
    "\n",
    "print('\\nClassical Model:')\n",
    "for metric in ['tm_score', 'rmsd', 'gdt_ts', 'plddt']:\n",
    "    mean = classical_results[metric].mean()\n",
    "    std = classical_results[metric].std()\n",
    "    print(f'  {metric.upper()}: {mean:.4f} ± {std:.4f}')\n",
    "\n",
    "print('\\nStatistical Significance:')\n",
    "print(f'  TM-score p-value: {tm_comparison[\"wilcoxon\"][\"p_value\"]:.4e}')\n",
    "print(f'  TM-score Cohen\\'s d: {tm_comparison[\"ttest\"][\"effect_size\"]:.4f}')\n",
    "print(f'  RMSD p-value: {rmsd_comparison[\"wilcoxon\"][\"p_value\"]:.4e}')\n",
    "\n",
    "if tm_comparison['wilcoxon']['p_value'] < CONFIG['alpha']:\n",
    "    print('  ✅ Statistically significant quantum advantage detected!')\n",
    "else:\n",
    "    print('  ⚠️  No significant difference detected. Consider more training.')\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('BENCHMARK COMPLETE!')\n",
    "print('='*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
