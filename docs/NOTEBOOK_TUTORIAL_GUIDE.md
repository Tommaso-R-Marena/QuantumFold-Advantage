# QuantumFold-Advantage: Complete Notebook Tutorial Guide

**Version:** 1.0  
**Date:** January 9, 2026  
**Format:** Video Tutorial Script / Interactive Walkthrough  
**Duration:** ~45 minutes (all notebooks)  
**Author:** QuantumFold Team

---

## üé¨ Tutorial Overview

This document serves as both a **video tutorial script** and an **interactive walkthrough** for all Colab notebooks in the QuantumFold-Advantage repository. Follow along step-by-step to master quantum-enhanced protein folding!

### What You'll Learn

‚úÖ Setting up Google Colab for quantum ML  
‚úÖ Loading and processing protein data  
‚úÖ Training quantum-enhanced models  
‚úÖ Evaluating with CASP metrics  
‚úÖ Creating publication-quality figures  
‚úÖ Statistical validation and hypothesis testing  
‚úÖ Troubleshooting common issues

### Prerequisites

- Google account (for Colab)
- Basic Python knowledge
- Understanding of machine learning concepts
- Familiarity with protein structure (helpful but not required)

---

## üì∫ Part 1: Quick Start (10 minutes)

### Opening the Notebook

**üé¨ [00:00 - 00:30]**

1. **Navigate to the repository:**
   - Go to https://github.com/Tommaso-R-Marena/QuantumFold-Advantage
   - Click on the `examples/` folder
   - Find `colab_quickstart.ipynb`

2. **Open in Colab:**
   - Click the "Open in Colab" badge at the top
   - OR: Copy the URL and visit `https://colab.research.google.com/github/...`

3. **Enable GPU (CRITICAL!):**
   ```
   Runtime > Change runtime type > Hardware accelerator > T4 GPU > Save
   ```
   
   **üí° Pro Tip:** Without GPU, training will be 10x slower!

---

### Installing Dependencies

**üé¨ [00:30 - 02:00]**

**Watch for:**
- üîÑ Progress bars during installation
- ‚úÖ Green checkmarks indicating success
- ‚ö†Ô∏è Yellow warnings (usually safe to ignore)
- ‚ùå Red errors (stop and troubleshoot)

**What's happening behind the scenes:**

```python
# Cell 1: Environment Check
if torch.cuda.is_available():
    print("GPU detected!")  # You should see this
```

**Expected output:**
```
‚úÖ Running in Google Colab
üêç Python: 3.10.12
üî• PyTorch: 2.1.0+cu121
‚ö° CUDA available: True
üéÆ GPU: Tesla T4
üíæ Memory: 15.0 GB
```

**üî¥ Troubleshooting:**
- **"CUDA available: False"** ‚Üí Enable GPU in Runtime settings
- **Import errors** ‚Üí Run the cell again (first run can be flaky)
- **Out of memory** ‚Üí Restart runtime: Runtime > Restart runtime

```python
# Cell 2: Install Dependencies
%%capture  # Suppresses verbose output
!pip install --quiet torch pennylane matplotlib ...
```

**Installation takes:** ~2 minutes  
**What gets installed:**
- PyTorch (deep learning)
- PennyLane (quantum computing)
- Matplotlib/Seaborn (visualization)
- BioPython (protein tools)
- NumPy, SciPy (scientific computing)

---

### Loading Protein Data

**üé¨ [02:00 - 03:30]**

```python
# Cell 3: Create Sample Protein
sequence = "MKTAYIAKQRQISFVKSHFSRQLEERLGLIEVQAPILSRVGDGTQDNLSGAEK"
n_residues = len(sequence)  # 54 residues
```

**What you're seeing:**
- **Sequence:** String of amino acid codes (M, K, T, A, Y, ...)
- **Coordinates:** 3D positions of each atom (x, y, z)
- **Structure:** Alpha-helix (corkscrew shape)

**üî¨ Deep Dive:**
```python
# Generate alpha-helix coordinates
t = np.linspace(0, 4*np.pi, n_residues)
coordinates[:, 0] = 2.3 * np.cos(t)  # X: radius * cos(angle)
coordinates[:, 1] = 2.3 * np.sin(t)  # Y: radius * sin(angle)  
coordinates[:, 2] = 1.5 * t          # Z: vertical rise
```

**Alpha-helix geometry:**
- Radius: 2.3 √Ö (angstroms)
- Pitch: 1.5 √Ö/residue
- Shape: Right-handed spiral

---

### Training the Model

**üé¨ [03:30 - 06:00]**

```python
# Cell 4: Initialize Model
model = SimpleProteinModel(input_dim=64, hidden_dim=128, output_dim=3)
```

**Architecture breakdown:**
```
Input (64) ‚Üí ReLU ‚Üí Hidden (128) ‚Üí ReLU ‚Üí Output (3)
                                             ‚Üì
                                        x, y, z coords
```

**Watch the training:**
```python
for epoch in range(10):
    loss = train_step(model, data)
    print(f"Epoch {epoch}: Loss = {loss:.4f}")
```

**Expected loss curve:**
```
Epoch 1: Loss = 15.3421
Epoch 2: Loss = 12.8934  # Decreasing = good!
Epoch 3: Loss = 10.2341
...
Epoch 10: Loss = 2.1234  # Final loss < 5 = success
```

**üî¥ Troubleshooting:**
- **Loss increasing?** ‚Üí Learning rate too high
- **Loss stuck?** ‚Üí Add more epochs or check data
- **NaN loss?** ‚Üí Restart and check for bugs

---

### Evaluating Results

**üé¨ [06:00 - 08:00]**

**CASP Metrics Explained:**

1. **RMSD (Root Mean Square Deviation)**
   - Measures average distance between atoms
   - **Lower is better**
   - < 2 √Ö = Excellent
   - 2-4 √Ö = Good
   - > 4 √Ö = Needs work

2. **TM-score (Template Modeling)**
   - Measures fold similarity (0 to 1)
   - **Higher is better**
   - > 0.8 = Same fold, high accuracy
   - 0.5-0.8 = Correct fold
   - < 0.5 = Different fold

**Example output:**
```
üéØ EVALUATION METRICS
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
RMSD: 1.847 √Ö          ‚úÖ Excellent!
TM-score: 0.823         ‚úÖ High accuracy!
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
```

---

### Visualizing Structures

**üé¨ [08:00 - 10:00]**

**You'll see three plots:**

1. **True Structure (Blue)**
   - Ground truth from experimental data
   - Color gradient = residue position

2. **Predicted Structure (Red)**
   - Model's prediction
   - Backbone trace shows connectivity

3. **Overlay (Blue + Red dashed)**
   - Direct comparison
   - How close? Closer = better!

**üí° Pro Tip:** Right-click and "Open image in new tab" to zoom in!

---

## üì∫ Part 2: Advanced Features (15 minutes)

### ESM-2 Protein Embeddings

**üé¨ [10:00 - 13:00]**

**What are embeddings?**
- AI-learned protein representations
- Captures evolutionary information
- 480 dimensions per residue

**Meta AI's ESM-2:**
- Trained on 65 million protein sequences
- Understands protein "language"
- State-of-the-art accuracy

```python
# Generate embeddings
embedder = ESM2Embedder(model_name='esm2_t12_35M_UR50D')
embeddings = embedder([sequence])
```

**Model sizes:**
- `esm2_t12_35M_UR50D`: 35M params, 150MB (Colab-friendly)
- `esm2_t33_650M_UR50D`: 650M params, 2.5GB (more accurate)
- `esm2_t36_3B_UR50D`: 3B params, 12GB (research grade)

**üî¥ Troubleshooting:**
```python
try:
    embeddings = embedder([sequence])
except Exception as e:
    print(f"ESM-2 failed: {e}")
    # Fallback to random embeddings
    embeddings = torch.randn(1, len(sequence), 480)
```

---

### Quantum-Enhanced Models

**üé¨ [13:00 - 17:00]**

**What makes it "quantum"?**

```python
class QuantumAttentionLayer:
    def __init__(self, n_qubits=4):
        # Create quantum circuit
        self.qnode = qml.QNode(self.circuit, dev)
```

**Quantum advantage:**
1. **Superposition** ‚Üí Explore multiple solutions simultaneously
2. **Entanglement** ‚Üí Capture long-range correlations
3. **Interference** ‚Üí Amplify correct solutions

**Visualizing quantum states:**
```
|œà‚ü© = Œ±|00‚ü© + Œ≤|01‚ü© + Œ≥|10‚ü© + Œ¥|11‚ü©
      ‚Üë      ‚Üë       ‚Üë       ‚Üë
    Amplitudes (complex numbers)
```

**In protein folding:**
- Each qubit = structural feature
- Circuit depth = model capacity
- Measurement = prediction

---

### Statistical Validation

**üé¨ [17:00 - 22:00]**

**Why statistics matter:**
- One result could be luck
- Need many samples + rigorous testing
- Required for publication

**Tests performed:**

1. **Wilcoxon Signed-Rank Test**
   - Non-parametric (no normal distribution assumption)
   - Tests if quantum > classical
   - P-value < 0.05 = significant

2. **Paired t-Test**
   - Parametric (assumes normal distribution)
   - Cohen's d = effect size
   - d > 0.8 = large effect

3. **Bootstrap Confidence Intervals**
   - Resample data 5000 times
   - Get 95% CI on difference
   - If CI excludes 0 ‚Üí significant

**Example interpretation:**
```python
Wilcoxon Test Results:
- P-value: 0.0023       ‚úÖ Significant!
- Effect size: 0.67     üìä Medium-large
- 95% CI: [0.012, 0.089] ‚úÖ Doesn't include 0

Conclusion: Quantum model is significantly better (p < 0.01)
```

---

### Publication-Quality Figures

**üé¨ [22:00 - 25:00]**

**Creating research-grade plots:**

```python
fig.savefig('results.png', dpi=300, bbox_inches='tight')
#                         ‚Üë         ‚Üë
#                      High res   No whitespace
```

**Best practices:**
- **DPI:** 300+ for publications
- **Format:** PNG for presentations, SVG for papers
- **Colors:** Colorblind-friendly palettes
- **Labels:** Clear, readable fonts (>10pt)
- **Legend:** Always include!

**Color schemes:**
- **Viridis:** Perceptually uniform
- **RdYlGn:** Red-Yellow-Green (confidence scores)
- **Paired:** Comparing two methods

---

## üì∫ Part 3: Quantum vs Classical Comparison (12 minutes)

**üé¨ [25:00 - 37:00]**

### Training Both Models

**Setup:**
```python
# Quantum model
quantum_model = QuantumModel(n_qubits=4)

# Classical baseline  
classical_model = ClassicalModel(same_parameters)

# Train on same data
for epoch in range(20):
    q_loss = train(quantum_model, data)
    c_loss = train(classical_model, data)
```

**What to watch:**
- **Quantum:** May start slower (circuit overhead)
- **Classical:** Faster initial training
- **Convergence:** Quantum may reach lower final loss

---

### Performance Comparison

**Metrics to compare:**

| Metric | Quantum | Classical | Winner |
|--------|---------|-----------|--------|
| Final Loss | 1.234 | 1.456 | üîµ Quantum |
| Train Time | 245s | 89s | üî¥ Classical |
| Accuracy | 87.3% | 84.1% | üîµ Quantum |
| Parameters | 12.4K | 15.8K | üîµ Quantum |

**Key insight:**
- Quantum: Better accuracy, fewer parameters
- Classical: Faster training (on classical hardware!)
- On real quantum hardware: Quantum would be faster

---

### Speed Calculation (FIX)

**‚ùå WRONG WAY:**
```python
speedup = c_total_time / q_total_time
print(f"Quantum is {speedup:.2f}x faster")
# This says "faster" even when slower!
```

**‚úÖ CORRECT WAY:**
```python
if q_total_time < c_total_time:
    speedup = c_total_time / q_total_time
    print(f"Quantum is {speedup:.2f}x FASTER")
else:
    slowdown = q_total_time / c_total_time  
    print(f"Quantum is {slowdown:.2f}x SLOWER")
    print("(Expected on classical hardware - quantum simulation overhead)")
```

---

## üì∫ Part 4: Advanced Visualization (8 minutes)

**üé¨ [37:00 - 45:00]**

### Interactive 3D Plots with Plotly

**‚ùå COMMON ERROR:**
```python
import plotly.graph_objects as go

fig = go.Figure(data=[
    go.Scatter3d(
        x=coords[:, 0],
        y=coords[:, 1],
        z=coords[:, 2],
        marker=dict(color=range(n))  # ‚ùå FAILS!
    )
])
```

**‚úÖ FIXED:**
```python
marker=dict(color=list(range(n)))  # ‚úÖ Works!
#                 ‚Üë‚Üë‚Üë‚Üë
#              Convert to list!
```

**Why?** Plotly can't serialize Python `range` objects to JSON.

---

### Distance and Contact Maps

**Creating distance matrix:**
```python
# Broadcasting magic
distances = np.sqrt(
    np.sum(
        (coords[:, None, :] - coords[None, :, :]) ** 2, 
        axis=2
    )
)
# Shape: (n_residues, n_residues)
```

**Interpretation:**
- **Diagonal:** Always 0 (distance to self)
- **Dark regions:** Residues close in space
- **Bright regions:** Far apart
- **Patterns:** Secondary structure (helices, sheets)

---

### Ramachandran Plots

**What are œÜ (phi) and œà (psi) angles?**

```
  C‚ÄîN‚ÄîCŒ±‚ÄîC‚ÄîN‚ÄîCŒ±‚ÄîC
    ‚Üë  ‚Üë   ‚Üë  ‚Üë
    œÜ  œà   œÜ  œà
```

**Allowed regions:**
- **Œ±-helix:** œÜ ‚âà -60¬∞, œà ‚âà -45¬∞
- **Œ≤-sheet:** œÜ ‚âà -120¬∞, œà ‚âà +120¬∞
- **Forbidden:** Steric clashes

**Good model ‚Üí Points cluster in allowed regions**

---

## üéØ Troubleshooting Guide

### Common Issues and Solutions

#### 1. GPU Not Available

**Symptom:**
```python
torch.cuda.is_available() == False
```

**Solution:**
1. Runtime > Change runtime type
2. Hardware accelerator > T4 GPU
3. Save
4. Runtime > Restart runtime

---

#### 2. Out of Memory

**Symptom:**
```
RuntimeError: CUDA out of memory
```

**Solutions:**
```python
# A) Clear cache
torch.cuda.empty_cache()

# B) Reduce batch size
batch_size = 8  # Instead of 16

# C) Use gradient accumulation
for i, batch in enumerate(loader):
    loss = loss / accumulation_steps
    loss.backward()
    
    if (i + 1) % accumulation_steps == 0:
        optimizer.step()
        optimizer.zero_grad()

# D) Enable mixed precision
from torch.cuda.amp import autocast
with autocast():
    output = model(input)
```

---

#### 3. Import Errors

**Symptom:**
```python
ImportError: cannot import name 'QuantumAttentionLayer'
```

**Solution:**
```python
# Check sys.path
import sys
print(sys.path)

# Add repository to path
sys.path.insert(0, '/content/QuantumFold-Advantage')

# Verify location
import os
print(os.getcwd())
print(os.listdir('src/'))
```

---

#### 4. Seaborn Style Deprecation

**Symptom:**
```python
UserWarning: The seaborn styles shipped by Matplotlib are deprecated
```

**Solution:**
```python
# OLD
plt.style.use('seaborn-darkgrid')

# NEW  
plt.style.use('seaborn-v0_8-darkgrid')

# OR just use default
plt.style.use('default')
sns.set_palette('husl')
```

---

#### 5. JAX Version Conflicts

**Symptom:**
```
TypeError: Cannot interpret 'DeviceArray' as a data type
```

**Solution:**
```python
# Uninstall conflicting versions
!pip uninstall -y jax jaxlib

# Install compatible versions
!pip install 'jax==0.4.23' 'jaxlib==0.4.23'

# Restart runtime
```

---

## üìù Summary and Next Steps

### What You Learned

‚úÖ Setting up Colab with GPU  
‚úÖ Installing quantum ML dependencies  
‚úÖ Loading and processing proteins  
‚úÖ Training quantum-enhanced models  
‚úÖ Statistical validation  
‚úÖ Creating publication figures  
‚úÖ Troubleshooting common issues

### Recommended Path

**Beginner:**
1. `colab_quickstart.ipynb` - Start here!
2. `03_advanced_visualization.ipynb` - Learn plotting
3. `02_quantum_vs_classical.ipynb` - Compare methods

**Advanced:**
1. `01_getting_started.ipynb` - Full features
2. `complete_benchmark.ipynb` - Publication pipeline
3. Modify for your own proteins!

### Going Further

**Try these:**
1. Upload your own PDB files
2. Modify hyperparameters
3. Add new evaluation metrics
4. Integrate with AlphaFold
5. Deploy on real quantum hardware

**Resources:**
- [PDB Database](https://www.rcsb.org/)
- [UniProt](https://www.uniprot.org/)
- [PennyLane Tutorials](https://pennylane.ai/qml/)
- [PyTorch Documentation](https://pytorch.org/docs/)

---

## üìß Support and Community

**Need help?**
- Open an issue: [GitHub Issues](https://github.com/Tommaso-R-Marena/QuantumFold-Advantage/issues)
- Read the docs: [Documentation](https://github.com/Tommaso-R-Marena/QuantumFold-Advantage/blob/main/README.md)
- Email: marena@cua.edu

**Want to contribute?**
- Fork the repository
- Create a feature branch
- Submit a pull request
- All contributions welcome!

---

## üèÜ Certification

**Completed this tutorial?** You now know:

‚úÖ Quantum machine learning basics  
‚úÖ Protein structure prediction  
‚úÖ Statistical hypothesis testing  
‚úÖ Scientific Python programming  
‚úÖ Publication-quality visualization  

**Add to your resume:**
- "Quantum-enhanced protein folding with PennyLane"
- "CASP evaluation metrics and benchmarking"
- "Statistical validation for computational biology"

---

## üìö References

1. **ESM-2:** Lin, Z., et al. (2023). Science, 379(6637)
2. **AlphaFold-3:** Abramson, J., et al. (2024). Nature
3. **PennyLane:** Bergholm, V., et al. (2018). arXiv:1811.04968
4. **Quantum ML:** Benedetti, M., et al. (2019). Quantum Science and Technology, 4(4)

---

**‚≠ê Star the repository if this helped!**  
**üëè Share with colleagues and students**  
**üöÄ Happy quantum protein folding!**

---

*Tutorial Version: 1.0*  
*Last Updated: January 9, 2026*  
*License: MIT*
